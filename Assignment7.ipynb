{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "behavioral-composer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import gzip\n",
    "import os\n",
    "import json\n",
    "import hashlib\n",
    "import shutil\n",
    "import pygeohash\n",
    "import s3fs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-project",
   "metadata": {},
   "source": [
    "# Assignment 7.1 a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "french-magic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the URL and directory path\n",
    "endpoint_url='https://storage.budsc.midwest-datascience.com'\n",
    "current_dir = Path(os.getcwd()).absolute()\n",
    "results_dir = current_dir.joinpath('results')\n",
    "\n",
    "if results_dir.exists():\n",
    "    shutil.rmtree(results_dir)\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def read_jsonl_data():\n",
    "    s3 = s3fs.S3FileSystem(\n",
    "        anon=True,\n",
    "        client_kwargs={\n",
    "            'endpoint_url': endpoint_url\n",
    "        }\n",
    "    )\n",
    "    src_data_path = 'data/processed/openflights/routes.jsonl.gz'\n",
    "    with s3.open(src_data_path, 'rb') as f_gz:\n",
    "        with gzip.open(f_gz, 'rb') as f:\n",
    "            records = [json.loads(line) for line in f.readlines()]\n",
    "    return records\n",
    "\n",
    "def flatten_record(record):\n",
    "    flat_record = dict()\n",
    "    \n",
    "    for key, value in record.items():\n",
    "        if key in ['airline', 'src_airport', 'dst_airport']:\n",
    "            if isinstance(value, dict):\n",
    "                for child_key, child_value in value.items():\n",
    "                    flat_key = '{}_{}'.format(key, child_key)\n",
    "                    flat_record[flat_key] = child_value\n",
    "        else:\n",
    "            flat_record[key] = value\n",
    "    return flat_record\n",
    "\n",
    "def create_flattened_dataset():\n",
    "    records = read_jsonl_data()\n",
    "    parquet_path = results_dir.joinpath('routes-flattened.parquet')\n",
    "    return pd.DataFrame.from_records([flatten_record(record) for record in records])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "approved-mississippi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "df = create_flattened_dataset()\n",
    "df['key'] = df['src_airport_iata'].astype(str) + df['dst_airport_iata'].astype(str) + df['airline_iata'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "demographic-beach",
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions = (\n",
    "        ('A', 'A'), ('B', 'B'), ('C', 'D'), ('E', 'F'),\n",
    "        ('G', 'H'), ('I', 'J'), ('K', 'L'), ('M', 'M'),\n",
    "        ('N', 'N'), ('O', 'P'), ('Q', 'R'), ('S', 'T'),\n",
    "        ('U', 'U'), ('V', 'V'), ('W', 'X'), ('Y', 'Z')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "optional-gabriel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove NaN values from the dataset\n",
    "df = df[df['src_airport_iata'].isna() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "interracial-visibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set kv-key equal to the first letter\n",
    "df['kv_key'] = df['key'].str[0]\n",
    "\n",
    "# Assign a value fromt he partitions list of tuples\n",
    "df['kv_key'] = df['kv_key'].apply(lambda x: [str('-'.join(partition)) for partition in partitions if (str(x) >= partition[0]) & (str(x) <= partition[1])])\n",
    "\n",
    "df['kv_key'] = [''.join(partition) for partition in df['kv_key']] \n",
    "\n",
    "# Replace the partitions that have the same start and end with a single letter\n",
    "df['kv_key'] = [partition[0] if partition[0] == partition[2] else partition for partition in df['kv_key']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "tender-literacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\n",
    "    path='results/kv', \n",
    "    partition_cols=['kv_key']\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-testimony",
   "metadata": {},
   "source": [
    "# Assignment 7.1 b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "delayed-dryer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Hash key\n",
    "def hash_key(key):\n",
    "    m = hashlib.sha256()\n",
    "    m.update(str(key).encode('utf-8'))\n",
    "    return m.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sonic-dubai",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hashed'] = df['key'].apply(lambda x: hash_key(x))\n",
    "df['hash_key'] = df['hashed'].str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "normal-profession",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_airline_id</th>\n",
       "      <th>airline_name</th>\n",
       "      <th>airline_alias</th>\n",
       "      <th>airline_iata</th>\n",
       "      <th>airline_icao</th>\n",
       "      <th>airline_callsign</th>\n",
       "      <th>airline_country</th>\n",
       "      <th>airline_active</th>\n",
       "      <th>src_airport_airport_id</th>\n",
       "      <th>src_airport_name</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_airport_dst</th>\n",
       "      <th>dst_airport_tz_id</th>\n",
       "      <th>dst_airport_type</th>\n",
       "      <th>dst_airport_source</th>\n",
       "      <th>codeshare</th>\n",
       "      <th>equipment</th>\n",
       "      <th>key</th>\n",
       "      <th>kv_key</th>\n",
       "      <th>hashed</th>\n",
       "      <th>hash_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>410</td>\n",
       "      <td>Aerocondor</td>\n",
       "      <td>ANA All Nippon Airways</td>\n",
       "      <td>2B</td>\n",
       "      <td>ARD</td>\n",
       "      <td>AEROCONDOR</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>True</td>\n",
       "      <td>2965.0</td>\n",
       "      <td>Sochi International Airport</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>Europe/Moscow</td>\n",
       "      <td>airport</td>\n",
       "      <td>OurAirports</td>\n",
       "      <td>False</td>\n",
       "      <td>[CR2]</td>\n",
       "      <td>AERKZN2B</td>\n",
       "      <td>A</td>\n",
       "      <td>652cdec02010381f175efe499e070c8cbaac1522bac59a...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>410</td>\n",
       "      <td>Aerocondor</td>\n",
       "      <td>ANA All Nippon Airways</td>\n",
       "      <td>2B</td>\n",
       "      <td>ARD</td>\n",
       "      <td>AEROCONDOR</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>True</td>\n",
       "      <td>2966.0</td>\n",
       "      <td>Astrakhan Airport</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>Europe/Moscow</td>\n",
       "      <td>airport</td>\n",
       "      <td>OurAirports</td>\n",
       "      <td>False</td>\n",
       "      <td>[CR2]</td>\n",
       "      <td>ASFKZN2B</td>\n",
       "      <td>A</td>\n",
       "      <td>9eea5dd88177f8d835b2bb9cb27fb01268122b635b241a...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>410</td>\n",
       "      <td>Aerocondor</td>\n",
       "      <td>ANA All Nippon Airways</td>\n",
       "      <td>2B</td>\n",
       "      <td>ARD</td>\n",
       "      <td>AEROCONDOR</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>True</td>\n",
       "      <td>2966.0</td>\n",
       "      <td>Astrakhan Airport</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>Europe/Moscow</td>\n",
       "      <td>airport</td>\n",
       "      <td>OurAirports</td>\n",
       "      <td>False</td>\n",
       "      <td>[CR2]</td>\n",
       "      <td>ASFMRV2B</td>\n",
       "      <td>A</td>\n",
       "      <td>161143856af25bd4475f62c80c19f68936a139f653c1d3...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>410</td>\n",
       "      <td>Aerocondor</td>\n",
       "      <td>ANA All Nippon Airways</td>\n",
       "      <td>2B</td>\n",
       "      <td>ARD</td>\n",
       "      <td>AEROCONDOR</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>True</td>\n",
       "      <td>2968.0</td>\n",
       "      <td>Chelyabinsk Balandino Airport</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>Europe/Moscow</td>\n",
       "      <td>airport</td>\n",
       "      <td>OurAirports</td>\n",
       "      <td>False</td>\n",
       "      <td>[CR2]</td>\n",
       "      <td>CEKKZN2B</td>\n",
       "      <td>C-D</td>\n",
       "      <td>39aa99e6ae2757341bede9584473906ef1089e30820c90...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>410</td>\n",
       "      <td>Aerocondor</td>\n",
       "      <td>ANA All Nippon Airways</td>\n",
       "      <td>2B</td>\n",
       "      <td>ARD</td>\n",
       "      <td>AEROCONDOR</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>True</td>\n",
       "      <td>2968.0</td>\n",
       "      <td>Chelyabinsk Balandino Airport</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>Asia/Krasnoyarsk</td>\n",
       "      <td>airport</td>\n",
       "      <td>OurAirports</td>\n",
       "      <td>False</td>\n",
       "      <td>[CR2]</td>\n",
       "      <td>CEKOVB2B</td>\n",
       "      <td>C-D</td>\n",
       "      <td>143b3389bce68eea3a13ac26a9c76c1fa583ec2bd26ea8...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   airline_airline_id airline_name           airline_alias airline_iata  \\\n",
       "0                 410   Aerocondor  ANA All Nippon Airways           2B   \n",
       "1                 410   Aerocondor  ANA All Nippon Airways           2B   \n",
       "2                 410   Aerocondor  ANA All Nippon Airways           2B   \n",
       "3                 410   Aerocondor  ANA All Nippon Airways           2B   \n",
       "4                 410   Aerocondor  ANA All Nippon Airways           2B   \n",
       "\n",
       "  airline_icao airline_callsign airline_country  airline_active  \\\n",
       "0          ARD       AEROCONDOR        Portugal            True   \n",
       "1          ARD       AEROCONDOR        Portugal            True   \n",
       "2          ARD       AEROCONDOR        Portugal            True   \n",
       "3          ARD       AEROCONDOR        Portugal            True   \n",
       "4          ARD       AEROCONDOR        Portugal            True   \n",
       "\n",
       "   src_airport_airport_id               src_airport_name  ... dst_airport_dst  \\\n",
       "0                  2965.0    Sochi International Airport  ...               N   \n",
       "1                  2966.0              Astrakhan Airport  ...               N   \n",
       "2                  2966.0              Astrakhan Airport  ...               N   \n",
       "3                  2968.0  Chelyabinsk Balandino Airport  ...               N   \n",
       "4                  2968.0  Chelyabinsk Balandino Airport  ...               N   \n",
       "\n",
       "  dst_airport_tz_id dst_airport_type dst_airport_source  codeshare  equipment  \\\n",
       "0     Europe/Moscow          airport        OurAirports      False      [CR2]   \n",
       "1     Europe/Moscow          airport        OurAirports      False      [CR2]   \n",
       "2     Europe/Moscow          airport        OurAirports      False      [CR2]   \n",
       "3     Europe/Moscow          airport        OurAirports      False      [CR2]   \n",
       "4  Asia/Krasnoyarsk          airport        OurAirports      False      [CR2]   \n",
       "\n",
       "        key  kv_key                                             hashed  \\\n",
       "0  AERKZN2B       A  652cdec02010381f175efe499e070c8cbaac1522bac59a...   \n",
       "1  ASFKZN2B       A  9eea5dd88177f8d835b2bb9cb27fb01268122b635b241a...   \n",
       "2  ASFMRV2B       A  161143856af25bd4475f62c80c19f68936a139f653c1d3...   \n",
       "3  CEKKZN2B     C-D  39aa99e6ae2757341bede9584473906ef1089e30820c90...   \n",
       "4  CEKOVB2B     C-D  143b3389bce68eea3a13ac26a9c76c1fa583ec2bd26ea8...   \n",
       "\n",
       "  hash_key  \n",
       "0        6  \n",
       "1        9  \n",
       "2        1  \n",
       "3        3  \n",
       "4        1  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "offshore-arabic",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\n",
    "    path='results/hash', \n",
    "    partition_cols=['hash_key']\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-numbers",
   "metadata": {},
   "source": [
    "# Assignment 7.1 c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "alternative-editor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'west': 'c21g6s0rs4c7', 'central': '9z7dnebnj8kb', 'east': 'dqby34cjw922'}\n"
     ]
    }
   ],
   "source": [
    "# Get hash for datacenters\n",
    "datacenters = {}\n",
    "\n",
    "datacenters['west'] = pygeohash.encode(45.5945645, -121.1786823)\n",
    "datacenters['central'] = pygeohash.encode(41.1544433, -96.0422378)\n",
    "datacenters['east'] = pygeohash.encode(39.08344, -77.6497145)\n",
    "\n",
    "print(datacenters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "internal-confidentiality",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cycle through the datacenter dictionary to assign the closest\n",
    "def closest_datacenter(latitude, longitude):\n",
    "    geohash = pygeohash.encode(latitude, longitude)\n",
    "    dist_dict = {}\n",
    "    closest_datacenter = ''\n",
    "    last_distance = None\n",
    "    for key, value in datacenters.items():\n",
    "        dist = pygeohash.geohash_approximate_distance(str(geohash), str(value))\n",
    "        dist_dict[key] = dist\n",
    "        if (last_distance == None) or (dist < last_distance):\n",
    "            closest_datacenter = key\n",
    "            last_distance = dist\n",
    "        \n",
    "    return closest_datacenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "elementary-platinum",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['datacenter'] = df[['src_airport_latitude', 'src_airport_longitude']].apply(lambda x: closest_datacenter(x[0], x[1]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "attempted-dispute",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\n",
    "    path='results/geo', \n",
    "    partition_cols=['datacenter']\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proud-hypothetical",
   "metadata": {},
   "source": [
    "# Assignment 7.1 d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "current-garden",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "def balance_partitions(keys, num_partitions):\n",
    "    partitions = []\n",
    "    \n",
    "    #get the ideal number of records in each partition\n",
    "    partition_size = len(keys) / num_partitions\n",
    "    \n",
    "    #get the count of records for each key\n",
    "    key_grp_cnts = []\n",
    "    for key in set(keys):\n",
    "        occurences = keys.count(key)\n",
    "        key_grp_cnts.append(tuple([key, occurences]))\n",
    "    \n",
    "    key_grp_cnts.sort(key=lambda v: v[0].lower())\n",
    "\n",
    "    total = 0\n",
    "    partition_list = []\n",
    "    #loop through the group counts until you exceed partition_size\n",
    "    for grp in key_grp_cnts:\n",
    "        \n",
    "        #if the total is 0, then this is the first key in the group\n",
    "        if total == 0:\n",
    "            min_grp = grp[0]\n",
    "            last_group = grp[0]\n",
    "\n",
    "       #if the incremented total exceeds the ideal partition size, then this key is the max group and reset the total\n",
    "        if  (total + grp[1]) > partition_size:\n",
    "            max_grp = last_group\n",
    "            partition_list.append(tuple([min_grp, max_grp]))\n",
    "            last_group = grp[0]\n",
    "            total=0\n",
    "        else:\n",
    "            last_group = grp[0]\n",
    "            total += grp[1]\n",
    "\n",
    "    #add last partition\n",
    "    partition_list.append(tuple([min_grp, last_group]))\n",
    "\n",
    "    return partition_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "early-commissioner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by using a series from the df above as the list of keys\n",
    "keys = list(df['airline_name'])\n",
    "num_partitions=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adjacent-association",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('40-Mile Air', 'Air Foyle'), ('Air Greenland', 'Amaszonas'), ('Amerijet International', 'China Eastern Airlines'), ('China SSS', 'Eurowings'), ('Excel Airways', 'Jet Airways'), ('JetBlue Airways', 'Omni Air International'), ('Onur Air', 'Shaheen Air International'), ('Shanghai Airlines', 'TransAsia Airways'), ('Transavia Holland', 'UTair-Express'), ('Valuair', 'Zoom Airlines')]\n"
     ]
    }
   ],
   "source": [
    "# Show the results\n",
    "print(balance_partitions(keys, num_partitions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
